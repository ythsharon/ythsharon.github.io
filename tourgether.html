<!doctype html>

<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <link rel="stylesheet" type="text/css" href="page.css">
    <link href="https://fonts.googleapis.com/css2?family=Josefin+Sans:wght@100;200;300;400&family=Poppins:wght@300;400&display=swap" rel="stylesheet">

<!-- Title -->    
    <title>Yi-Ting</title>
    <link rel="shortcut icon" type="image/x-icon" href="shortcut.png"/>
<link rel="canonical" href="https://yitingtw.github.io"/>
</head>

<!-- Body -->
<body>
<!-- Navigation -->
<div class="page">
    <nav>
        <div class="nav-container">
            <div class="nav-left">
                <a href="index.html">
                  <h3>Yi Ting</h3>
                </a>
            </div>
            <div class="nav-right">
                <ul>
                  <li class="active"><a href="index.html">Research</a></li>
                  <li><a href="project.html">Project</a></li>
                  <li><a href="playground.html">Playground</a></li>
                  <li><a href="index.html">About</a></li>
                </ul>
            </div>
        </div>
    </nav>

	<div class="content-container">
		<section class="intro">
		  <h2>Who Do You Want to Provide the Information ? </h2>
		  	<h3 class="title-note">A Preliminary Exploration of Expected Experiences from Location-Based Mobile Crowdsourcing Contributors</h3>
		  <br>
		  <h3>OVERVIEW</h3>
		  <p>Regarding this research, interviews with interviewees and qualitative analysis have been completed. Currently we are doing surveys to obtain quantitative data. After obtaining quantitative data and analyzing, we will submitted the poster to CHI Late-Breaking Work 2022.<br><br>
		  	* The poster attached below is about our former preliminary research.

		  	<br><br></p>

		  <h3>INTRODUCTION</h3>
		  <p>Mobile crowdsourcing enables its users to learn about location-related information from people with diverse experiences and opinions. However, little research investigates the information quality most relevant to the location-related questions expected by the users from the crowd, as well as the experiences users expect the contributors to possess to answer these questions, respectively. We conducted an interview study (N=22) that extracted six information properties of location-based questions, identified ten users’ desired information qualities for these questions - reliability, temporal relevancy, degree of context, enjoyability, novelty, specificity, understandability, completeness, recency, and objectivity, and finally seven aspects of desired experience from contributors - period of residence, quantity, recency, regularity, variety, professional relevancy, and engagement in commentary. A follow-up survey study (N=139) then investigates characteristics of a list of location-related questions respondents perceive according to their information properties. <br><br></p>
		  

		  <h3>ROLE</h3>
		  <p>Researcher<br><br></p>

		  <h3>COLLABORATORS</h3>
		  <p>Fang-Yu Lin</p>
		  <p class="note">National Yang Ming Chiao Tung University</p>
		  <p>Chia-Yi Lee</p>
		  <p class="note">National Yang Ming Chiao Tung University<br><br></p>

		  <h3>ADVISOR</h3>
		  <p>Prof. Yung-Ju Chang</p>
		  <p class="note">MUI Lab / National Yang Ming Chiao Tung University</p>
		  <p>Prof. Yu-Chun Yen</p>
		  <p class="note">University of California San Diego<br><br><br></p>

		  <h3>INTERVIEW</h3>
		  <p>We conducted semi-structured interviews with 22 participants (12 males; 10 females) who had experience in seeking location-based information or providing location-based information online. <br></p>
		  <p>In the interview we asked participants what kinds of information they had experience in obtaining or would hope to obtain from location-based crowdsourcing platforms, respectively. Then, we asked them what kinds of experience and backgrounds they would expect or desire the contributors on the platforms to possess. Our aim was to prompt participants to reflect on the similarities and contrasts in the experiences the desired for various kinds of location-related information. Through the comparison and contrasting process, we hoped to identify the key properties of the location-related information they were seeking that distinguished the information qualities they expected, as well as the experiences they desired from the contributors to possessed, respectively. To facilitate and diversify such comparisons, we provided a pile of cards (see the figure below) that offered various examples of location-related experiences and information. The purpose of these cards was to provide participants with some materials as inspirations or cues that helped them recall their prior experiences in acquiring and seeking the same, similar, or other different but relevant information. The development of cards was iterative–new cards were added to the pile whenever the researchers learned new types of location-related experiences or information that was mentioned in the interview. A total of 23 types of location-based information and 11 types of experiences cards was developed.<br></p>
		  <img class="tourgether_img" src="tourgether_interview.png"><br><br>

		  <h3>DATA ANALYSIS</h3>
		  <p>We conducted thematic analysis of our interview data using the qualitative analysis software MAXQDA3. Generation of the codebook was guided by our research questions - identifying the key properties of location-related information participants would hope to obtain via crowdsourcing, the information qualities they expected for the information, and the aspects of experiences they desired the contributor to possess. To ensure the reliability of our coding process, three researchers first coded interview transcripts from three participants independently and discussed the codes together. In the origin session. For each coded transcript, the coders compared and discussed the discrepancies and clarity of the codes until full consensus was reached. After all discrepancies were resolved, they updated the codebook.<br></p>
		  <img class="tourgether_img" src="tourgether_analysis.png" width=""><br><br>

		  <h3>PRELIMINARY INSIGHTS</h3>
		  <img class="tourgether_img" src="tourgether_result.png">
		  <p>To sum up, the interview results showed that people would consider different qualities and different expected experience based on different information properties on location-related crowdsourcing platforms. The requested information could be described with 6 properties corresponding to 10 information qualities. Furthermore, according to the desired information qualities, 7 characteristics of the expected experience of contributors were reported important, including period of residence, quantity, recency, regularity, variety, professional relevancy, and engagement in commentary. Our interview results indicate that the type of requested information influenced the information seekers’ expectations on the contributors’ experience. To further verify the results, future research would quantitatively examine the correspondence between requested information items and qualities as well as the correspondence between requested information items and expected experiences.<br><br></p>
		  

		  <h3>SURVEY</h3>
		  <p>Before we conduct the quantitative research to verify the relationship between the above factors, a survey was made to decide which information items were representative enough (i.e., both common for most people and also diverse in properties) that can be enrolled in the quantitative research. We developed an online questionnaire and enrolled the location-based information that was usually seen both in the crowdsourcing papers and in our interview. These information items included food review, product supply status, product price, crowd, activity content, public device’s condition, region’s (pollution, security, and etc.) issue, parking, scene description, and recommendations in the region.<br><br></p>


		  <h3>CONCLUSION AND FUTURE WORK</h3>
		  <p>Our qualitative results indicate that people require different information qualities when seeking different types of location-based information on crowdsourcing platforms and this may also influence the information seekers’ expectation on the contributors’ experience, suggesting that mobile crowdsourcing platforms should take such correspondence into account when assigning tasks to contributors. As a result, we will include the information items that are found to be also common and diverse in the preliminary survey and conduct quantitative research to examine the correspondence among information types, information qualities, and expected experience.<br></p>
		  <img src="">

		</section>

		<section >
			<div>
				<!--img class="tourgether_img" src="tourgether.jpg"-->
				<br><br><br>
			</div>
			<div >
				<!--img class="tourgether_img" src="process_overview.png"-->
				<br><br>
			</div>
			
		</section>
		<section>
		  <div >
			  <iframe src="tourgether.pdf" height="768px"></iframe>
		  </div>

		  <br><br>
		</section>

		
	</div>

<!-- Footer -->
    <footer class="footer">
      <div class="copyright">Copyright © 2020 Yi-Ting Ho</div>
      <div class="social-media">
        <a href="https://dribbble.com/bunnieabc"><img src="#" alt=""></a>
        <a href="https://github.com/bunnieabc"><img src="#" alt=""></a>
        <a href="mailto:yhl437@nyu.edu"><img src="#" alt=""></a>
        <a href="https://www.linkedin.com/in/yu-hsuan-lin-06772ab8/"><img src="#" alt=""></a>
      </div>
    </footer>


</div>
</body>
</html>